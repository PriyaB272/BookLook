{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\Anaconda2\\envs\\cs670\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2718: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "df = pd.read_csv('BX-Book-Ratings.csv', names=[\"User-ID\", \"ISBN\", \"Book-Rating\"], delimiter=\";\")\n",
    "rating_matrix = numpy.ndarray(shape=(50000,50000), dtype = 'int64')\n",
    "df_mat = df.as_matrix()[1:]\n",
    "#print(df_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_mat' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store df_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149780\n"
     ]
    }
   ],
   "source": [
    "%store -r df_mat\n",
    "totalratings = len(df_mat[:,0])\n",
    "print totalratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "print (type(df_mat[:,0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_mat[:,0] = df_mat[:,0].astype('int64')\n",
    "df_mat[:,2] = df_mat[:,2].astype('int64')\n",
    "\n",
    "usercount = (len(np.unique(df_mat[:,0])))\n",
    "bookcount = (len(np.unique(df_mat[:,1])))\n",
    "#numpy.unique(df_mat[:,1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "print (type(df_mat[:,0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105283\n",
      "340556\n"
     ]
    }
   ],
   "source": [
    "print usercount\n",
    "print bookcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookid = 0\n",
    "usernum = 0\n",
    "bookmap = {}\n",
    "usermap = {}\n",
    "useridslist = []\n",
    "for k in range(0,800000):\n",
    "    userid = df_mat[k,0]\n",
    "    isbn = df_mat[k,1]\n",
    "    if isbn not in bookmap:\n",
    "        if bookid < 50000:\n",
    "            bookmap[isbn] = bookid\n",
    "            if userid not in usermap:\n",
    "                if usernum < 50000:\n",
    "                    usermap[userid]=usernum\n",
    "                    rating_matrix[usernum, bookid] = df_mat[k,2]\n",
    "                    usernum+=1\n",
    "            else:\n",
    "                rating_matrix[usermap[userid], bookid] = df_mat[k,2]\n",
    "            bookid = bookid+1\n",
    "    else:\n",
    "        if userid not in usermap:\n",
    "            if usernum < 50000:\n",
    "                usermap[userid]=usernum\n",
    "                rating_matrix[usernum, bookmap[isbn]] = df_mat[k,2]\n",
    "                usernum+=1\n",
    "        else:\n",
    "            rating_matrix[usermap[userid], bookmap[isbn]] = df_mat[k,2]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000L, 50000L)\n"
     ]
    }
   ],
   "source": [
    "print(rating_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105283\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "user_list = np.unique(df_mat[:,0])\n",
    "print len(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print len(bookmap.values())\n",
    "print len(usermap.values())\n",
    "\n",
    "#print df_mat[0,0]\n",
    "#print bookmap[df_mat[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing a bipartite graph\n",
    "\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(usermap.values(), bipartite=0) #0 indicates one class of nodes, here: users\n",
    "B.add_nodes_from(bookmap.values(), bipartite=1) #1 for isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "500000\n",
      "550000\n",
      "600000\n",
      "650000\n",
      "700000\n",
      "750000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nls.append()\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_ls = []\n",
    "\n",
    "for k in range(0,800000):\n",
    "    ls = []\n",
    "    if k%50000==0:\n",
    "        print k\n",
    "    if df_mat[k,0] in usermap.keys() and df_mat[k,1] in bookmap.keys() and df_mat[k,2]!=0:\n",
    "        ls.append(usermap[df_mat[k,0]])\n",
    "        ls.append(bookmap[df_mat[k,1]])\n",
    "        if df_mat[k,2] > 6:\n",
    "            rate = 'L' # for love\n",
    "        else: rate = 'H' # for hate\n",
    "        ls.append(rate)\n",
    "        edge_ls.append(ls)\n",
    "#print edge_ls\n",
    "B.add_weighted_edges_from(edge_ls)\n",
    "\n",
    "'''\n",
    "ls.append()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# from networkx.algorithms import bipartite\n",
    "\n",
    "# B = nx.Graph()\n",
    "# B.add_nodes_from(usermap.values(), bipartite=0)\n",
    "# B.add_nodes_from(bookmap.values(), bipartite=1)\n",
    "\n",
    "# edge_ls = []\n",
    "# for i in range(0,50000):\n",
    "#     for j in range(0,50000):\n",
    "#         if rating_matrix[i,j] !=0:\n",
    "#             ls = []\n",
    "#             ls.append(i)\n",
    "#             ls.append(j)\n",
    "#             if rating_matrix[i,j] > 6:\n",
    "#                 rate = 'L' # for love\n",
    "#             else: \n",
    "#                 rate = 'H' # for hate\n",
    "#             ls.append(rate)\n",
    "#             edge_ls.append(ls)\n",
    "# B.add_weighted_edges_from(edge_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r B\n",
    "import pickle\n",
    "pickle.dump(B,open(\"a.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached user  1\n",
      "Reached user  10001\n",
      "Reached user  20001\n",
      "Reached user  30001\n",
      "Reached user  40001\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#B= pickle.load(open(\"a.p\",\"rb\"))\n",
    "from collections import defaultdict\n",
    "Dictionary = defaultdict(dict)\n",
    "count =0\n",
    "dictionary_adj = dict(B.adjacency()) \n",
    "for user1 in usermap.values():\n",
    "    BFS_Dict= dict(nx.bfs_successors(B,user1))\n",
    "    User_item_list = []\n",
    "    User_item_list.append(user1)\n",
    "    edge_list=[]\n",
    "    if count%10000 ==0:\n",
    "        print \"Reached user \",count+1\n",
    "    count+=1\n",
    "    if bool(BFS_Dict):\n",
    "        for book1 in BFS_Dict[user1]:\n",
    "            if book1 in BFS_Dict.keys():\n",
    "                edge_list.append(dictionary_adj[user1][book1]['weight'])\n",
    "                for user2 in BFS_Dict[book1]:\n",
    "                    edge_list.append(dictionary_adj[book1][user2]['weight'])    \n",
    "                    '''\n",
    "                    if count%100 ==0:\n",
    "                        print \"Hello\"\n",
    "                        print dictionary_adj[user2]\n",
    "                        print BFS_Dict[user1]\n",
    "                    '''\n",
    "                    for book2 in dictionary_adj[user2].keys(): \n",
    "                        if book2 in BFS_Dict[user1] and book2!=book1:\n",
    "                            edge_list.append(dictionary_adj[user2][book2]['weight'])\n",
    "                            User_item_list.append(book2)\n",
    "                            Dictionary[tuple(User_item_list)][tuple(edge_list)] = Dictionary[tuple(User_item_list)].get(tuple(edge_list),0)+1\n",
    "                            Dictionary[tuple(User_item_list)][\"Rating\"]=rating_matrix[User_item_list[0]][User_item_list[1]]\n",
    "                            edge_list.pop()\n",
    "                            User_item_list.pop()\n",
    "                    edge_list.pop()\n",
    "                edge_list.pop()\n",
    "            \n",
    "#print(Dictionary)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161293\n"
     ]
    }
   ],
   "source": [
    "print (len(Dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'Dictionary' (defaultdict)\n"
     ]
    }
   ],
   "source": [
    "%store Dictionary\n",
    "import pickle\n",
    "pickle.dump(Dictionary,open(\"b.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming all configurations\n",
    "con = []\n",
    "\n",
    "con.append([('H', 'H', 'H')])\n",
    "con.append([('H', 'H', 'L')])\n",
    "con.append([('H', 'L', 'L')])\n",
    "con.append([('L', 'L', 'L')])\n",
    "con.append([('L', 'L', 'H')])\n",
    "con.append([('L', 'H', 'H')])\n",
    "con.append([('H', 'L', 'H')])\n",
    "con.append([('L', 'L', 'L')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r Dictionary\n",
    "import numpy as np\n",
    "config_mat = np.zeros((len(Dictionary), 9))\n",
    "pair_dic = {}\n",
    "i=0\n",
    "for k in Dictionary.keys():\n",
    "    userItemConfig = Dictionary[k]\n",
    "    pair_dic[i] = k\n",
    "    for key in userItemConfig.keys():\n",
    "        for j in range(0,8):\n",
    "            if con[j][0] == key:\n",
    "                config_mat[i,j] = userItemConfig[key]\n",
    "    if rating_matrix[k[0],k[1]]!=0:\n",
    "        if rating_matrix[k[0],k[1]] > 6:\n",
    "            config_mat[i,-1] = 1\n",
    "        else: config_mat[i,-1] = 0\n",
    "    #config_mat[i,-1] = rating_matrix[k[0],k[1]] \n",
    "    i+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161293\n"
     ]
    }
   ],
   "source": [
    "print(len(config_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'config_mat' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store config_mat\n",
    "import pickle\n",
    "pickle.dump(config_mat,open(\"c.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...  0.  1.  1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]\n",
      " [ 0.  0.  0. ...  0.  1.  0.]\n",
      " ...\n",
      " [ 0.  1. 10. ...  1.  8.  0.]\n",
      " [ 0.  0.  0. ...  1.  3.  0.]\n",
      " [ 0.  1.  2. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "%store -r config_mat\n",
    "print(config_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(config_mat[:,0:8], config_mat[:,-1], test_size=0.30, shuffle=False)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48388\n"
     ]
    }
   ],
   "source": [
    "mnb_y_pred = mnb.predict(X_test)\n",
    "print len(mnb_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with Naive Bayes: 0.66533580754\n"
     ]
    }
   ],
   "source": [
    "#print len(y_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, mnb_y_pred))\n",
    "print \"RMSE with Naive Bayes:\",rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train' (ndarray)\n",
      "Stored 'X_test' (ndarray)\n",
      "Stored 'y_train' (ndarray)\n",
      "Stored 'y_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store X_train\n",
    "%store X_test\n",
    "%store y_train\n",
    "%store y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with kNN: 0.665118341998\n"
     ]
    }
   ],
   "source": [
    "%store -r X_train\n",
    "%store -r X_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "KNN_y_pred = knn.predict(X_test)\n",
    "rmse_knn = sqrt(mean_squared_error(y_test, KNN_y_pred))\n",
    "print \"RMSE with kNN:\", rmse_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_mat_book' (ndarray)\n",
      "Stored 'bookmap' (dict)\n",
      "Stored 'usermap' (dict)\n",
      "Stored 'pair_dic' (dict)\n",
      "Stored 'lr_y_pred' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store df_mat_book\n",
    "%store bookmap\n",
    "%store usermap\n",
    "%store pair_dic\n",
    "%store lr_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " USER ID:  79278  BOOK NAME:  The Toilet Paper Tigers  PREDICTED:  Love  ACTUAL:  Love\n",
      " USER ID:  16795  BOOK NAME:  The Diving Bell and the Butterfly : A Memoir of Life in Death  PREDICTED:  Hate  ACTUAL:  Love\n",
      " USER ID:  179716  BOOK NAME:  The Drawing of the Three (The Dark Tower, Book 2)  PREDICTED:  Hate  ACTUAL:  Hate\n",
      " USER ID:  135143  BOOK NAME:  Defy Not The Heart  PREDICTED:  Hate  ACTUAL:  Hate\n",
      " USER ID:  19707  BOOK NAME:  The Color of Water: A Black Man's Tribute to His White Mother  PREDICTED:  Hate  ACTUAL:  Hate\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "%store -r X_train\n",
    "%store -r y_test\n",
    "%store -r lr_y_pred\n",
    "%store -r df_mat_book\n",
    "%store -r usermap\n",
    "%store -r bookmap\n",
    "%store -r pair_dic\n",
    "\n",
    "\n",
    "from random import randint\n",
    "isbn =[row[0] for row in df_mat_book]\n",
    "book_name =[row[1] for row in df_mat_book]\n",
    "count=0\n",
    "# 5922 , 23938 \n",
    "offset_train = len(X_train)\n",
    "offset_test = len(y_test)\n",
    "while(count<5):\n",
    "    rnd = randint(0,offset_test-1)\n",
    "    #print pair_dic[rnd][0]\n",
    "    if lr_y_pred[rnd] == 0:\n",
    "        lr_p = 'Hate'\n",
    "    else : lr_p = 'Love'\n",
    "    if y_test[rnd] == 0:\n",
    "        yt_p = 'Hate'\n",
    "    else : yt_p = 'Love'   \n",
    "    if isbn.count(bookmap.keys()[bookmap.values().index(pair_dic[rnd+offset_train][1])])!=0:\n",
    "        print \" USER ID: \",usermap.keys()[usermap.values().index(pair_dic[rnd+offset_train][0])],\n",
    "        print \" BOOK NAME: \",book_name[isbn.index(bookmap.keys()[bookmap.values().index(pair_dic[rnd+offset_train][1])])],\n",
    "        print \" PREDICTED: \",lr_p,\" ACTUAL: \",yt_p\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df_book = pd.read_csv('BX-Books.csv', names=[\"ISBN\",\"Book-Title\",\"Book-Author\",\"Year-Of-Publication\",\"Publisher\",\"Image-URL-S\",\"Image-URL-M\",\"Image-URL-L\"], delimiter=\";\")\n",
    "# df_mat_book = df_book.as_matrix()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with SVM: 0.629274668368\n"
     ]
    }
   ],
   "source": [
    "%store -r X_train\n",
    "%store -r X_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "clf = LinearSVC()\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "svc_y_pred = clf.predict(X_test)\n",
    "rmse_svc = sqrt(mean_squared_error(y_test, svc_y_pred))\n",
    "print \"RMSE with SVM:\", rmse_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with Decision tree: 0.633529668826\n"
     ]
    }
   ],
   "source": [
    "%store -r X_train\n",
    "%store -r X_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "dt_y_pred = dt.predict(X_test)\n",
    "rmse_dt = sqrt(mean_squared_error(y_test, dt_y_pred))\n",
    "print \"RMSE with Decision tree:\", rmse_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with Logistic Regression: 0.628995454256\n"
     ]
    }
   ],
   "source": [
    "%store -r X_train\n",
    "%store -r X_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "lr = lr.fit(X_train, y_train)\n",
    "lr_y_pred = lr.predict(X_test)\n",
    "rmse_lr = sqrt(mean_squared_error(y_test, lr_y_pred))\n",
    "print \"RMSE with Logistic Regression:\", rmse_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
